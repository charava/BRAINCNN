# -*- coding: utf-8 -*-
"""Brain_Tumor_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pbhqvQWusk_nTAmELEcfwEsDqqLfy63D
"""

!pip install -U -q PyDrive
import os
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder
from torch.optim import SGD
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torchvision import datasets, transforms
from tqdm import tqdm
from PIL import Image
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/ML/CNN/CNN Project/Brain Tumor/

# hypee parameteesss
BATCH_SIZE = 16
EPOCHS = 10
LEARNING_RATE = 0.001
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# data transformations - including normalization
train_transforms = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

# Data loader for training data
data_dir = 'Training/'
train_dataset = datasets.ImageFolder(data_dir, transform=train_transforms)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
CLASSES = train_dataset.classes

# model architecture
model = nn.Sequential(
    nn.Conv2d(3, 1000, kernel_size=3),
    nn.ReLU(),
    nn.MaxPool2d(2),
    nn.Conv2d(1000, 100, kernel_size=3),
    nn.ReLU(),
    nn.MaxPool2d(2),
    nn.Conv2d(100, 128, kernel_size=3),
    nn.ReLU(),
    nn.MaxPool2d(2),
    nn.Flatten(),
    nn.Linear(128 * 30 * 30, 512),
    nn.ReLU(),
    nn.Dropout(0.5),
    nn.Linear(512, 4),
)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

model.to(DEVICE)

train_loss = []
for e in range(EPOCHS):
    print(f"Training epoch {e}!")
    for batch_idx, (data, target) in tqdm(enumerate(train_loader)):
        data, target = data.to(DEVICE), target.to(DEVICE)
       
        output = model(data)
        
        loss = criterion(output, target)
        
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        
        train_loss.append(loss.item())
        
        predictions = torch.argmax(output, axis=1)
        accuracy = (sum(predictions == target)/BATCH_SIZE).item()
        
    print(f"Done with epoch {e}! Last accuracy {accuracy}")
    print('epoch {}, loss {}'.format(e, loss.item()))

# convert the list to a tensor
train_loss_tensor = torch.tensor(train_loss)

# plot the training loss
plt.plot(train_loss_tensor)
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

# Loading test data
test_transforms = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

test_data_dir = 'Testing/'
test_dataset = datasets.ImageFolder(test_data_dir, transform=test_transforms)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

# Validation
correct = 0
total = 0
model.eval()
with torch.no_grad():
    for data, target in tqdm(test_loader):
        data, target = data.to(DEVICE), target.to(DEVICE)
        
        # Forward pass
        output = model(data)
        
        # Get predictions from the maximum value
        # _, predicted = torch.max(output.data, 1)
        predicted = torch.argmax(output, dim=1)

        
        # Update correct and total predictions
        total += target.size(0)
        correct += (predicted == target).sum().item()

print(f"Test accuracy: {correct/total}")





### OTHER CODE FORMAT BELOW ###





#### CONSTANTS / HYPERPARAMETERS ####

# Define hyperparameters
BATCH_SIZE = 16
EPOCHS = 10
LEARNING_RATE = 0.001 # 0.01 #3e-3
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

### CHECKING IF IM ON THE GPU ###
if torch.cuda.is_available():
    device = torch.device("cuda")
    print(f"GPU {torch.cuda.get_device_name(0)} is available.")
else:
    device = torch.device("cpu")
    print("No GPU available, using CPU instead.")

### PREPPING DATA AND DATA LOADER ###

# Defining transforms for data normalization
train_transforms = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

# Loading and normalizing data
train_data_dir = 'Training/'
train_dataset = datasets.ImageFolder(train_data_dir, transform=train_transforms)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)


# test_data_dir = 'Testing/'
# test_transform = transforms.Compose([transforms.Resize((256, 256)), 
#                                      transforms.ToTensor(),
#                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
#                                     ])# took out transforms.CenterCrop(224)
# test_dataset = datasets.ImageFolder(test_data_dir, transform=test_transform)
# test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)


CLASSES = train_dataset.classes  # ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']


# images, labels = next(iter(dataloader)) # this is just to check if batching is working

class BRAINCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv0 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)
        self.conv1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4)
        self.pool = nn.MaxPool2d(kernel_size=2) # takes the max value in the kernal (tells you if its bright), avg tells you if its smooth out (overall trend in area)
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=6)
        self.flat = nn.Flatten()
        self.linear1 = nn.Linear(1843200, 512)
        self.linear2 = nn.Linear(512,16)
        self.linear3 = nn.Linear(16, 4)
        self.dropout = nn.Dropout(0.5)
        self.softmax = nn.Softmax(1) # finding distribution for each value in batch size with "1"
        self.relu = nn.ELU()

    def forward(self, x): # this runs the layers
        x = self.relu(self.conv0(x))
        x = self.relu(self.conv1(x))
        x = self.pool(x)
        x = self.relu(self.conv2(x))
        x = self.flat(x)
        x = self.relu(self.linear1(x))
        x = self.relu(self.linear2(x))
        x = self.relu(self.linear3(x))
        x = self.softmax(x)
        return x

# class BRAINCNN(nn.Module):
#     def __init__(self):
#         super().__init__()
#         self.conv0 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3)
#         self.conv1 = nn.Conv2d(in_channels=64, out_channels=100, kernel_size=4)
#         self.pool = nn.MaxPool2d(kernel_size=2) # takes the max value in the kernal (tells you if its bright), avg tells you if its smooth out (overall trend in area)
#         self.conv2 = nn.Conv2d(in_channels=100, out_channels=10, kernel_size=6)
#         self.flat = nn.Flatten()
#         self.linear1 = nn.Linear(144000, 16)
#         self.linear2 = nn.Linear(16,16)
#         self.linear3 = nn.Linear(16, 4)
#         self.softmax = nn.Softmax(1) # finding distribution for each value in batch size with "1"
#         self.relu = nn.ELU()

#     def forward(self, x): # this runs the layers
#         x = self.relu(self.conv0(x))
#         x = self.relu(self.conv1(x))
#         x = self.pool(x)
#         x = self.relu(self.conv2(x))
#         x = self.flat(x)
#         x = self.relu(self.linear1(x))
#         x = self.relu(self.linear2(x))
#         x = self.relu(self.linear3(x))
#         x = self.softmax(x)
#         return x





# Define the model architecture
# model = nn.Sequential(
#     nn.Conv2d(3, 32, kernel_size=3),
#     nn.ReLU(),
#     nn.MaxPool2d(2),
#     nn.Conv2d(32, 64, kernel_size=3),
#     nn.ReLU(),
#     nn.MaxPool2d(2),
#     nn.Conv2d(64, 128, kernel_size=3),
#     nn.ReLU(),
#     nn.MaxPool2d(2),
#     nn.Flatten(),
#     nn.Linear(128 * 30 * 30, 512),
#     nn.ReLU(),
#     nn.Dropout(0.5),
#     nn.Linear(512, 4),
# )

model = BRAINCNN().to(DEVICE)
criterion = nn.CrossEntropyLoss().to(DEVICE)
optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

# Train the model
train_loss = []
with torch.cuda.device(DEVICE):
  for e in range(EPOCHS):
    print(f"Training epoch {e}!")
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(DEVICE), target.to(DEVICE)
        
        # Compute output
        output = model(data)
        
        # Calculate loss
        loss = criterion(output, target)
        
        # Backprop operations
        loss.backward()
        optim.step()
        optim.zero_grad()
        
        train_loss.append(loss.item())
        
        # Calculate accuracy
        predictions = torch.argmax(output, axis=1)
        accuracy = (sum(predictions == target)/BATCH_SIZE).item()
        
    print(f"Done with epoch {e}! Last accuracy {accuracy}")
    print('epoch {}, loss {}'.format(e, loss.item()))

# convert the list to a tensor
train_loss_tensor = torch.tensor(train_loss)

# plot the training loss
plt.plot(train_loss_tensor)
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

# This calculates accuracy
def get_accuracy(pred_arr,original_arr):
    pred_arr = pred_arr.detach().numpy()
    original_arr = original_arr.numpy()
    final_pred= []

    for i in range(len(pred_arr)):
        final_pred.append(np.argmax(pred_arr[i]))
    final_pred = np.array(final_pred)
    count = 0

    for i in range(len(original_arr)):
        if final_pred[i] == original_arr[i]:
            count+=1
    return count/len(final_pred)*100


output_test = model(X_test)
print(get_accuracy(output_test, y_test))





#### CODE DUMPING GROUNDS BELOW!! ######





#### GETTING THE Y DATA ####

training_y_dict = {}
for x in range(len(labels)):
  subfolder = 'Training/' + labels[x] + '/'
  for i in os.listdir(subfolder):
    training_y_dict[i] = labels[x]

testing_y_dict = {}
for x in range(len(labels)):
  subfolder = 'Testing/' + labels[x] + '/'
  for i in os.listdir(subfolder):
    new_i = labels[x] + '/' + i 
    testing_y_dict[new_i] = labels[x]


##### TRAINING KEY ######
# glioma tumor (training) = gg ([number])
# no_tumor (training)
# pituitary_tumor (testing) = p ([number])
# meningioma_tumor (testing) = m ([number]) // m1 // m2 // m3

##### TESTING KEY ######
# glioma tumor (testing) = image([number])
# no_tumor (testing) = image([number])
# pituitary_tumor (testing) = image([number])
# meningioma_tumor (testing) = image([number]) --- note that one image is just image.jpg

class MyDataset(Dataset):
    def __init__(self, labels, transform=None):
        self.labels = labels
        self.transform = transform
    
    def __len__(self):
        return len(self.labels)
    
    def __getitem__(self, idx):
        label = self.labels[idx]
        subfolder = 'Training/' + label + '/'
        images = []
        for i in os.listdir(subfolder):
            img = Image.open(subfolder + i)
            img = img.resize((256, 256)) # resize the image
            if self.transform:
                img = self.transform(img)
            images.append(img)
            img.close()
        return torch.stack(images, dim=0), label
      
batch_size = 32
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])

dataset = MyDataset(labels)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

batch_sizes = []
for batch_idx, (data, target) in enumerate(dataloader):
    batch_sizes.append(data[0].shape)
    
print("Batch sizes:", batch_sizes)
# and remember, whatever I do for training, I need to do for testing.

# Convert the list to a tensor
train_loss = torch.tensor(train_loss)

fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(12, 6), sharex=True)

ax2.plot(train_loss.cpu(), linewidth=1.5)  # Call cpu() on the tensor
ax2.set_ylabel("training loss")

ax3.set_xlabel("epochs")

class MyDataset(Dataset):
    def __init__(self, labels):
        self.labels = labels
    
    def __len__(self):
        return len(self.labels)
    
    def __getitem__(self, idx):
        label = self.labels[idx]
        subfolder = 'Training/' + label + '/'
        filename = os.listdir(subfolder)[0] # get the first file in the subfolder
        img = Image.open(subfolder + filename)
        img = img.resize((256, 256)) # resize the image
        arr = np.array(img)
        arr = arr.swapaxes(0, 2)
        arr = arr / 255
        img.close()
        return arr, label




batch_size = 32
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])

dataset = MyDataset(labels)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

for batch_idx, (data, target) in enumerate(dataloader):
    print(data)
  
  

# and remember, whatever I do for training, I need to do for testing.

#### GETTING THE X DATA ####



x_arr = []

for x in range(len(labels)):
  subfolder = 'Training/' + labels[x] + '/'
  for i in os.listdir(subfolder):
    filename = subfolder + i 
    img = Image.open(filename)
    arr = np.array(img)
    arr = arr.swapaxes(0,2)
    arr = arr/255   
    x_arr.append(arr)
    img.close()
  break
    

x_data = np.array(x_arr)
x_data = torch.tensor(x_data, device=DEVICE).float()
# x_data = x_data.unsqueeze(0)

label_ids = defaultdict(lambda:len(label_ids))

# >>> label_ids["frog"] => 0
# >>> label_ids["truck"] => 1
# >>> label_ids["truck"] => 1
# >>> label_ids["deer"] => 2
# >>> label_ids["frog"] => 0


# one hot encode the labeles
enc = OneHotEncoder(handle_unknown='ignore')
result = enc.fit_transform(np.array(y.label).reshape(-1, 1)).toarray()
y_data = torch.LongTensor(result, device=DEVICE)

# label econde
# le = preprocessing.LabelEncoder()
# label_encoded=le.fit_transform(np.array(y.label))
# y2_data = torch.LongTensor(label_encoded)



y_id = '1ai-DYxO1osJBn2OHRrxt-1hV8pyE8SEv' # y data
y_downloaded = drive.CreateFolder({'id':y_id}) 
y_downloaded.GetContentFile('archive (6) 3')  
y = pd.read_csv('archive (6).zip', index_col=0)

!unzip "/content/gdrive/MyDrive/ML/CNN/archive (6).zip" -d "/content/gdrive/MyDrive/ML/CNN/"

# patoolib.extract_archive('archive (6).zip')

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder
from torch.optim import SGD
import torch
import torch.nn as nn
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from sklearn import preprocessing
from collections import defaultdict
from torch.utils.data import DataLoader, TensorDataset
from tqdm import tqdm
import os


import torch
from torch.utils import data
import os
import numpy as np

# !pip install dicom2nifti
# import dicom2nifti
import nibabel as nib
# import nilearn as nil
import scipy.ndimage as ndi
import matplotlib.pyplot as plt
import os

# 3D CNN for BOLD 5000
# https://github.com/harsharaman/bold5000_fmri

# import torch
# from torch import nn as nn
# from torch.nn import functional as F
# from torch.utils import data

# class fMRICNN(nn.Module):
#     def __init__(self):
#         super(fMRICNN, self).__init__()        
#         self.conv1 = nn.Conv3d(5, 16, kernel_size=7, stride=2)
#         self.conv2 = nn.Conv3d(16, 32, kernel_size=5, stride=2)
#         self.conv3 = nn.Conv3d(32, 64, kernel_size=3, stride=2)
#         self.classifier = nn.Conv3d(64, 10, kernel_size=1, stride=2)
#         self.tanh = nn.Tanh()
                                                                            
#     def forward(self, input_tensor):
#         x = self.conv1(input_tensor)
#         x = self.tanh(x)
#         x = self.conv2(x)
#         x = self.tanh(x)
#         x = self.conv3(x)
#         x = self.tanh(x)
#         x = self.classifier(x)
#         return x
                                                                                                                                                        
# net = fMRICNN()
# x = torch.randn(35,5,91,109,91)
# out = net(x)
# print(out.shape)

"""Try using Weights and Biases

Image Augmentation

Set up GPU
"""

class fMRICNNcustomDataset(data.Dataset):
    """
    Args:
    fmri_data (string): Path to the fmri file with masks.
    fmri_label (string): Path to respective label of fmri (to which class it belongs to)
    fmri_labelname (string): Path to respective labelname of fmri
    transform (callable, optional): Optional transform to be applied on a sample.
    """
    def __init__(self, data_folder):
        self.path_list = []
        self.root_folder = data_folder
        self.sub_list = ['CSI!', 'CSI2', 'CSI3', 'CSI4']
        for path, subdirs, files in os.walk(self.root_folder):
            for name in files:
                if '.p' in name:
                    self.path_list.append(os.path.join(path,name))

    def __len__(self):
        'denotes the total number of samples'
        return len(self.path_list)

    def __getitem__(self, index):
        'Generates one sample of data'
        if torch.is_tensor(index):
            idx = idx.tolist()
        
        x_data = np.array(torch.load(self.path_list[index])['X'])
        y_cluster = np.array(torch.load(self.path_list[index])['y'])
        return x_data, y_cluster

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/ML/CNN/BOLDDataset/ds001499-download/

sub_CSI1_folder = '/content/gdrive/MyDrive/ML/CNN/BOLDDataset/ds001499-download/derivatives/fmriprep/sub-CSI1/figures/'

# Get a list of items in the folder
sub_CSI1_folder_items = os.listdir(sub_CSI1_folder)

# Print the list of items

sub_CSI1_item_names = []
for item in sub_CSI1_folder_items:
  if ('bold_bbr' in item) and ('run' in item):
    sub_CSI1_item_names.append(item)

!pip install svgutils.transform

svg_filename = sub_CSI1_folder + str(sub_CSI1_item_names[100])

img = Image.open(svg_filename)
arr = np.array(img)

# Load the SVG content from file
with open(svg_filename, 'r') as f:
    svg_xml = f.read()
    display(SVG(svg_xml))


!pip install svgpathtools
import svgpathtools
import numpy as np

# Replace 'example.svg' with the name of your SVG file
doc = svgpathtools.Document(svg_filename)

# Convert the SVG to a Numpy array
img = svgpathtools.paths2array(doc.paths, height=200, width=200)

# Print the shape of the array
print(img.shape)



# Load the NIfTI image file
img = nib.load('/content/ds001499-download/derivatives/fmriprep/sub-CSI1/anat/sub-CSI1_T1w_class-CSF_probtissue.nii.gz')

# Display some basic information about the image
print(f"Image shape: {img.shape}")
print(f"Image data type: {img.get_data_dtype()}")
print(f"Image affine matrix:\n{img.affine}")

'''
neuroimaging software packages such as FSL, SPM, or AFNI to analyze and process the data.
'''

data = img.get_fdata() # Once the image is loaded, you can access its data array using img.get_fdata().

plt.imshow(data[50], cmap='bone')
plt.axis('off')
plt.show()

#### CONSTANTS ####

TRAIN_SPLIT = 0.9
EPOCHS = 3
BATCH_SIZE = 16
LR = 3e-3

SAMPLE_COUNT = 50000 # this is exogenously known by checking the ./data folder

DEVICE = torch.device("cuda:0" if torch cuda.is_available() else "cpu")
DEVICE

#### GETTING THE X DATA ####
x_arr = []
for i in range(1,50001):
  filename = '/content/data/' + str(i) + '.png'
  img = Image.open(filename)
  arr = np.array(img)
  # arr = arr[:,:,:-1] dont need bc img not transparent
  arr = arr.swapaxes(0,2)
  arr = arr/255
  x_arr.append(arr)
  img.close()

x_data = np.array(x_arr)
x_data = torch.tensor(x_data, device=DEVICE).float()
# x_data = x_data.unsqueeze(0)

#### GETTING THE Y DATA ####
y_id = '1IKBKXJGizQmqHnHL9UWb8Gx4am1toGls' # y data
y_downloaded = drive.CreateFile({'id':y_id}) 
y_downloaded.GetContentFile('y.csv')  
y = pd.read_csv('y.csv', index_col=0)

label_ids = defaultdict(lambda:len(label_ids))

# >>> label_ids["frog"] => 0
# >>> label_ids["truck"] => 1
# >>> label_ids["truck"] => 1
# >>> label_ids["deer"] => 2
# >>> label_ids["frog"] => 0


# one hot encode the labeles
enc = OneHotEncoder(handle_unknown='ignore')
result = enc.fit_transform(np.array(y.label).reshape(-1, 1)).toarray()
y_data = torch.LongTensor(result, device=DEVICE)

# label econde
# le = preprocessing.LabelEncoder()
# label_encoded=le.fit_transform(np.array(y.label))
# y2_data = torch.LongTensor(label_encoded)

# "TRAIN TEST SPLITTING"
train_count = int(SAMPLE_COUNT*TRAIN_SPLIT)
val_count = SAMPLE_COUNT-train_count 

train_x = x_data[:int(train_count)]
train_y = y_data[:train_count] 

val_x = x_data[train_count:] 
val_y = y_data[train_count:]

train_dataset = TensorDataset(torch.tensor(train_x, device=DEVICE).float(),
                              torch.tensor(train_y, device=DEVICE).float())
val_dataset = TensorDataset(torch.tensor(val_x, device=DEVICE).float(),
                            torch.tensor(val_y, device=DEVICE).float())

# Great, we now create a DataLoader for the training data,
# batching the data as well.
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)

# # BATCHING
# train_X_batches = []
# train_y_batches = []
# for i in range(0, train_count-BATCH_SIZE, BATCH_SIZE):
#   train_X_batches.append(train_x[i:i+BATCH_SIZE])
#   train_y_batches.append(train_x[i:i+BATCH_SIZE])



class THECNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv0 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3)
        self.conv1 = nn.Conv2d(in_channels=10, out_channels=5, kernel_size=4)
        self.pool = nn.MaxPool2d(kernel_size=2) # takes the max value in the kernal (tells you if its bright), avg tells you if its smooth out (overall trend in area)
        self.conv2 = nn.Conv2d(in_channels=5, out_channels=5, kernel_size=6)
        self.flat = nn.Flatten()
        self.linear1 = nn.Linear(320, 16)
        self.linear2 = nn.Linear(16,16)
        self.linear3 = nn.Linear(16, 10)
        self.softmax = nn.Softmax(1) # finding distribution for each value in batch size with "1"
        self.relu = nn.ELU()

    def forward(self, x): # this runs the layers
        x = self.relu(self.conv0(x))
        x = self.relu(self.conv1(x))
        x = self.pool(x)
        x = self.relu(self.conv2(x))
        x = self.flat(x)
        x = self.relu(self.linear1(x))
        x = self.relu(self.linear2(x))
        x = self.relu(self.linear3(x))
        x = self.softmax(x)
        return x

model = THECNN().to(DEVICE)
criterion = nn.CrossEntropyLoss()
optim = torch.optim.Adam(model.parameters(), lr=LR)

with torch.cuda.device(DEVICE):
  for e in range(EPOCHS):
    print(f"Training epoch {e}!")

    for x,y in tqdm(iter(train_loader), total=len(train_loader)): # wrapping a loop with tqdm will print a fancy loading bar on screen which you can use to track progress of training a batch. It is transparent in all other respects
                                                                  # and will just dump the output of iter(train_loader)
                                                             # so this loop is effectively just `for x,y in iter(train_loader):`
        # compute output
        output = model(x)

        # calculate loss
        loss = criterion(output, y)

        # backprop operations
        loss.backward()
        optim.step()
        optim.zero_grad()

        # calculate accuracy
        # torch.argmax(*, axis=1) essentially un-onehot encodes
        # computing the *INDICIES* for predictions and targets
        predictions = torch.argmax(output, axis=1)
        targets = torch.argmax(y, axis=1)

        # accuracy, then, checks if the two are equal, then
        # add up all the "True" (corresponding to 1) in that list
        # Dividing this by the batch size will then give us the
        # mean accuracy in that batch.
        accuracy = (sum(predictions == targets)/BATCH_SIZE).item()

    print(f"Done with epoch {e}! Last accuracy {accuracy}")

for i in range(EPOCHS):
  for X,y in zip(train_X_batches, train_y_batches):
    output = model(X.float())
    loss = criterion(output, y.float())
    loss.backward()
    optim.step()
    optim.zero_grad()

    # predictions = torch.argmax(output, axis=1)
    # targets= torch.argmax(y,axis=1)



# THIS IS WHERE I LEFT OFF

# This calculates accuracy
def get_accuracy(pred_arr,original_arr):
    pred_arr = pred_arr.detach().numpy()
    original_arr = original_arr.numpy()
    final_pred= []

    for i in range(len(pred_arr)):
        final_pred.append(np.argmax(pred_arr[i]))
    final_pred = np.array(final_pred)
    count = 0

    for i in range(len(original_arr)):
        if final_pred[i] == original_arr[i]:
            count+=1
    return count/len(final_pred)*100

fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(12, 6), sharex=True)

ax2.plot(train_loss,linewidth=1.5)
ax2.set_ylabel("training loss")

ax3.set_xlabel("epochs")

train_loss=[]

for i in range(1,50001):
  filename = '/content/data/' + str(i) + '.png'
  img = Image.open(filename)
  arr = np.array(img)
  # arr = arr[:,:,:-1] dont need bc img not transparent
  arr = arr.swapaxes(0,2)
  brightness_arr = arr/255
  img_tsr = torch.tensor(brightness_arr).float()
  img_tsr = img_tsr.unsqueeze(0)



  output_train = model(img_tsr)
  print(y_data[i])
  print(output_train.reshape(-1))

  #calculate the loss
  loss = criterion(output_train, y_data[i])
  # loss = criterion(output_train, y_data[SI:EI])
  print(loss)
  train_loss.append(round(loss.item(), 4))

  #backward propagation: calculate gradients
  loss.backward()
  # SI += batchsize
  # EI += batchsize

  #update the weights
  optimizer.step()

  #clear out the gradients from the last step loss.backward()
  optimizer.zero_grad()

  if (i + 1) % 2 == 0:
        print(f"Epoch {i+1}/{num_epochs}, Train Loss: {loss.item()}")

for i in y['id']:
  filename = '/content/data/' + str(i) + '.png'
  img = Image.open(filename)
  arr = np.array(img)

  arr = arr[:,:,:-1]
  arr = arr.swapaxes(0,2)
  brightness_arr = arr/255
  img_tsr = torch.tensor(brightness_arr).float()
  img_tsr = img_tsr.unsqueeze(0)

  output_train = model(img_tsr)
  print(output_train)

  #calculate the loss
  print(y_data)


  loss = criterion(output_train, y_data)
  train_loss.append(round(loss.item(), 4))

  #backward propagation: calculate gradients
  loss.backward()
 

  #update the weights
  optimizer.step()

  #clear out the gradients from the last step loss.backward()
  optimizer.zero_grad()





# test_convolution_layer = nn.Conv2d(in_channels=2,
# out_channels=5,
# kernel_size=4,
# stride=(1,1))

# net = test_convolution_layer(img_tsr)

# test_pooling_layer = nn.MaxPool2d(kernel_size=4,
# stride=(1,1))
# net = test_pooling_layer(net)

# flat = nn.Flatten()